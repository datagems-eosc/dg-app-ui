{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DataGEMS Frontend &amp; Design Overview","text":"<p>This is the central documentation site for the DataGEMS Frontend application, which serves as the primary user interface (UI) for the entire DataGEMS platform.</p> <p>The Frontend service acts as the presentation layer, focused on delivering a high-performance, intuitive, and consistent user experience for dataset discovery, management, and AI interaction. It translates complex API structures into clear, manageable workflows for end-users.</p>"},{"location":"#key-documentation-areas","title":"Key Documentation Areas","text":"<p>You can use the navigation menu to the left to explore the various aspects of the DataGEMS UI and its underlying architecture.</p> <p>You may be interested to jump directly to:</p> <ul> <li>Architecture &amp; Tech Stack: A deep dive into why we chose Next.js 15 (App Router), React 19, and Tailwind CSS to achieve our performance and design goals. This section covers our use of TypeScript and NextAuth.js with Keycloak.</li> <li>Design System &amp; Components: Details on our UI Kit, including reusable components (like the <code>DatasetTile</code>) and the principles driving visual consistency, accessibility, and user experience across all views.</li> <li>Feature Workflows: Step-by-step guides on complex user interactions, such as Advanced Filtering, Custom Collection Management, and the AI Chat Interface with source tracking and collection scoping.</li> <li>Performance &amp; Reliability: Documentation on our state management strategy (React Context), API caching principles, and how we address common issues like data synchronization delays.</li> </ul>"},{"location":"#further-assistance","title":"Further Assistance","text":"<p>For specific questions regarding the UI implementation, please consult the Frontend FAQ, check if a relevant Issue already exists, or contact the DataGEMS Help Desk.</p>"},{"location":"architecture/","title":"Service Architecture","text":""},{"location":"architecture/#technical-stack-deep-dive","title":"Technical Stack Deep Dive","text":"<p>The DataGems Frontend is engineered for efficiency, data integrity, and architectural resilience. The core technologies define the application's comprehensive performance and maintenance profile, ensuring reliable operation within data-intensive workflows.</p>"},{"location":"architecture/#framework-and-architecture","title":"Framework and Architecture","text":"<p>The application's foundational structure is built upon Next.js 15, strategically utilizing the App Router to enforce modern rendering and data-fetching paradigms. Next.js is the designated full-stack React framework, managing the entire process chain encompassing routing, compilation, and code splitting. This framework selection is pivotal for maximizing performance through a hybrid rendering strategy. Specifically, the implementation leverages Server Components to execute rendering logic and initial data fetching on the server. This mechanism significantly reduces the size of the JavaScript bundle transmitted to the client and minimizes client-side computational load, reserving client resources for complex interactivity. The DataGems implementation exploits this capability to achieve a sub-second Largest Contentful Paint (LCP), which is a critical performance metric for a platform displaying large, dynamic data catalogues and ensuring immediate perceived responsiveness.</p>"},{"location":"architecture/#core-development-languages","title":"Core Development Languages","text":"<p>The entire codebase is constructed with React 19 and strictly implemented using TypeScript. React provides the declarative, component-driven model necessary for managing the complex user interactions inherent in the platform, allowing for isolated state management and predictable updates. TypeScript, a superset of JavaScript, is a mandatory requirement across all modules. It introduces static typing and compilation-time checks that eliminate an entire class of runtime errors, resulting in substantial improvements to code quality, safety during large-scale refactoring operations, and overall developer experience. The enforcement of strong typing is essential for validating and managing the diverse and evolving metadata schemas associated with external datasets, thereby ensuring robust data integrity throughout the application's state management layer.</p>"},{"location":"architecture/#styling-and-ui-consistency","title":"Styling and UI Consistency","text":"<p>Styling is systematically implemented using Tailwind CSS, integrated alongside a dedicated library of Custom UI Components. Tailwind CSS operates as a utility-first framework, generating styling based on atomic utility classes applied directly within the markup. This approach replaces complex, abstracted CSS class systems with composable utility chains, effectively reducing developer context switching and minimizing the risk of unintended style regressions. This methodology ensures the rapid and precise implementation of complex visual elements, such as dynamic side panels, adaptive layouts, and state-dependent controls. The integration guarantees high fidelity to the design specification and absolute visual consistency across the entire DataGems design system.</p>"},{"location":"architecture/#security-and-authentication-layer","title":"Security and Authentication Layer","text":"<p>Authentication and authorization are managed by the NextAuth.js library, which securely interfaces with our Keycloak identity provider. NextAuth.js provides a secure and flexible abstraction layer responsible for handling user sessions and JSON Web Tokens (JWTs). The implementation specifically utilizes the OAuth 2.0 Authorization Code Flow with PKCE (Proof Key for Code Exchange). This robust security protocol mitigates the risk of token-hijacking vulnerabilities, even in public client environments like web browsers. Utilizing this industry-standard, secure flow is paramount for a platform managing access to potentially restricted datasets, as it ensures strict compliance with security standards and safeguards user access credentials.</p>"},{"location":"architecture/#authentication-secure-login-via-keycloak","title":"Authentication: Secure login via Keycloak","text":"<p>The user login mechanism is delegated entirely to the external Keycloak Identity and Access Management (IAM) service. The frontend initiates the login process by redirecting the user's browser to the Keycloak authorization endpoint, adhering strictly to the OpenID Connect (OIDC) specification. Upon successful verification of user credentials by Keycloak, the service issues an Authorization Code back to the Next.js API layer. This code is then securely exchanged for the full set of JWT tokens (ID Token, Access Token, Refresh Token) using the secured PKCE method. This separation of concerns ensures that the DataGems frontend never handles or stores sensitive user passwords, offloading the responsibility of credential management and advanced security policies (such as MFA) to the dedicated Keycloak service.</p>"},{"location":"architecture/#data-visualization-and-mapping","title":"Data Visualization and Mapping","text":"<p>For the accurate and efficient display of geospatial data, the frontend employs a strategic, hybrid technology approach. The Google Maps API is utilized to handle the foundational rendering of base map layers, standard location services, and familiar user interaction paradigms. This is critically combined with MapLibre GL, an open-source library specialized in hardware-accelerated rendering of vector tiles. This combination allows the platform to leverage the global coverage and quality of Google Maps while using MapLibre GL's capabilities to achieve superior performance when rendering custom, data-intensive overlays derived directly from our source datasets, avoiding the UI thread blocking and performance degradation often associated with large-scale raster rendering.</p>"},{"location":"architecture/#frontend-architecture-layers","title":"Frontend Architecture Layers","text":"<p>The DataGems Frontend is structured into distinct, logical layers to ensure robust separation of concerns, enhance testability, and facilitate maintainability across a large application scale. The following layers govern data flow, presentation logic, and system integration.</p>"},{"location":"architecture/#presentation-layer","title":"Presentation Layer","text":"<p>This layer is solely responsible for the visual rendering of the user interface and the precise handling of all direct user interaction events. The implementation utilizes React Client Components to manage dynamic state, process event listeners, and maintain a highly interactive user experience. Client Components execute exclusively within the user's browser environment, providing the necessary environment for managing granular element lifecycles, complex visual effects, and local component state. This distinction from Server Components is critical for features demanding immediate DOM manipulation, such as the dynamic filtering of datasets, the immediate update of the \"Selected Datasets\" panel, and the complex input handling within the AI Chat Interface.</p>"},{"location":"architecture/#state-management-layer","title":"State Management Layer","text":"<p>Global and domain-specific application state is managed using the native React Context API. This method provides a centralized, yet logically partitioned, mechanism for reliable state distribution across the component tree without introducing external, monolithic state management libraries. Dedicated Context Providers are defined for each major application domain: Dataset, Collections, and User. Components retrieve necessary data and dispatch state-modifying actions via custom hooks tightly coupled to these specific Contexts. This structure ensures a straightforward and unidirectional data flow, effectively mitigating \"prop drilling\" while fully leveraging the native rendering optimizations provided by React for state changes. It guarantees immediate access to essential structural data, such as authentication status from the User Context, and large data structures like the current list of available Datasets.</p>"},{"location":"architecture/#api-communication-layer","title":"API Communication Layer","text":"<p>All network communication between the frontend client and the external backend microservices is securely routed through Next.js API routes. This layer functions as a mandatory intermediary, fulfilling the role of a BFF (Backend for Frontend) pattern. Client-side requests are dispatched to localized Next.js endpoints (e.g., <code>/api/datasets</code>). These server-side routes then execute several critical functions: they manage the secure injection of authentication tokens, handle any necessary data aggregation or transformation, and reliably forward the request to the designated upstream backend service. The utilization of Next.js API routes significantly enhances the security posture by preventing the exposure of sensitive backend service URLs and internal API keys directly to the client browser, while simultaneously allowing for precise data shaping to optimize payloads for UI consumption.</p>"},{"location":"architecture/#authentication-and-authorization","title":"Authentication and Authorization","text":"<p>User authorization is managed via JWT-based tokens, with the overall session lifecycle fully controlled by NextAuth.js, which integrates securely with the Keycloak identity provider. Upon successful user authentication, the system issues a JSON Web Token (JWT). This token is then securely maintained and automatically attached to all subsequent outbound requests originating from the Next.js API layer. This mechanism allows for the efficient authorization of access to protected backend resources and enforces granular dataset permissions. Reliance on JWTs ensures a stateless and highly scalable authentication model, where authorization decisions can be executed by resource services with minimal latency.</p>"},{"location":"architecture/#deployment-environment","title":"Deployment Environment","text":"<p>The application's deployment and operational lifecycle are strictly managed via containerization using Docker and orchestrated within a Kubernetes cluster environment. Docker provides standardized, immutable, and isolated environments for the Next.js application, ensuring perfect consistency between development, staging, and production environments. Kubernetes handles advanced service scaling, automated self-healing capabilities, and efficient load balancing across replicas. Crucially, configuration variances between deployment stages (e.g., API endpoints, security secrets) are managed meticulously using environment overlays. This robust container-based strategy ensures high availability, simplifies the continuous delivery pipeline, and guarantees that sensitive configuration is securely segregated across all operational stages.</p>"},{"location":"automations/","title":"Automations","text":"<p>A number of automations are available to facilitate the development, quality assurance, security, deployment, maintenance and onboarding of the service. Here we describe some that are directly, publicly available.</p>"},{"location":"automations/#dockerfile","title":"Dockerfile","text":"<p>The main delivery package for the service is a docker image. The Dockerfile bundled under the Http Api project for the service builds the Docker image.</p>"},{"location":"automations/#docker-image-publishing","title":"Docker image publishing","text":"<p>A GitHub Action workflow is available to build and publish the generated docker image for the service. The action is triggered when a new tag is created in the repository with a pattern of v*. This way, all the images produced are always named and can be traced back to the codebase snapshot that generated them.</p> <p>The generated docker image is pushed to the GitHub organization Packages using the name of the service repo and the version tag that triggered the execution.</p>"},{"location":"automations/#vulnerability-scanning","title":"Vulnerability Scanning","text":"<p>A GitHub Action workflow is available to scan for vulnerabilities any docker image that was created for the service. The action is triggered manually and expects as input the version tag that was used to generate the respective docker image that must be scanned.</p> <p>Vulnerability scanning is performed using Trivy. The results are generated in SARIF format and are made available in the GitHub Code Scanning tool that is configured for the service.</p> <p>Trivy is utilized to scan both the configuration that triggers the Docker image generation (ie the Dockerfile) as well as the generated image. The scanning performed on the generated image includes both OS vulnerabilities as well as installed libraries.</p>"},{"location":"automations/#static-code-analysis","title":"Static Code Analysis","text":"<p>A GitHub Action workflow is available to analyze the code using static code analysis offered through GitHub's CodeQL. The action is triggered manually and can be executed against the HEAD of the repository.</p> <p>The scan is configured to evaluate rules on security, quality and maintenability of the codebase. The results generated are made available in the GitHub Code Scanning tool that is configured for the service.</p>"},{"location":"automations/#code-metrics","title":"Code Metrics","text":"<p>A GitHub Action workflow is available to generate code metrics using ASP.NET Core msbuild targets. The action is triggered manually and can be executed against the HEAD of the repository.</p> <p>The generated metrics includes useful insight on metrics such as: * Maintenability index * Cyclomatic Complexity * Class Coupling * Depth of Inheritance * Lines of code</p> <p>The metrics are generated for the hierarchy of the code base, including Assembly, Namespace, Class, Method. This provides navigable insight. The results generated are in custom msbuild xml format and are available as action artefacts.</p>"},{"location":"automations/#documentation","title":"Documentation","text":"<p>A GitHub Action workflow is available to generate documentation available in the project in the format presented here. The action is triggered manually and can be executed against the head of the repository. The documentatino generated is versioned and the documentation version is expected as input to the workflow. </p> <p>The documentation is build using the mkdocs library and specifically using the Material for mkdocs plugin. A number of additional tools are ustilized, such as mike to support versioning, neoteroi.mkdocsoad to support OpenAPI specification rendering, and others.</p> <p>The documentation is generated and tagged with the provided version. It is uploaded to a dedicated documentation branch that is configured to be used as the base branch over which the repository GitHub Page presents its contents.</p>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"deployment/","title":"Deployment","text":"<p>The service is part of the DataGEMS platform offered through an existing deployment, following the DataGEMS release and deployment procedures over a managed infrasrtucture. The purpose of this section is not to detail the deployment processes put in place by the DataGEMS team.</p>"},{"location":"deployment/#docker","title":"Docker","text":""},{"location":"deployment/#configuration","title":"Configuration","text":""},{"location":"deployment/#dependencies","title":"Dependencies","text":""},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"faq/#is-datagems-really-that-awsome","title":"Is DataGEMS really that awsome?","text":"<p>Yes, it is.</p>"},{"location":"license/","title":"License","text":"<pre><code>                  EUROPEAN UNION PUBLIC LICENCE v. 1.2\n                  EUPL \u00a9 the European Union 2007, 2016\n</code></pre> <p>This European Union Public Licence (the \u2018EUPL\u2019) applies to the Work (as defined below) which is provided under the terms of this Licence. Any use of the Work, other than as authorised under this Licence is prohibited (to the extent such use is covered by a right of the copyright holder of the Work).</p> <p>The Work is provided under the terms of this Licence when the Licensor (as defined below) has placed the following notice immediately following the copyright notice for the Work:</p> <pre><code>    Licensed under the EUPL\n</code></pre> <p>or has expressed by any other means his willingness to license under the EUPL.</p> <ol> <li>Definitions</li> </ol> <p>In this Licence, the following terms have the following meaning:</p> <ul> <li> <p>\u2018The Licence\u2019: this Licence.</p> </li> <li> <p>\u2018The Original Work\u2019: the work or software distributed or communicated by the   Licensor under this Licence, available as Source Code and also as Executable   Code as the case may be.</p> </li> <li> <p>\u2018Derivative Works\u2019: the works or software that could be created by the   Licensee, based upon the Original Work or modifications thereof. This Licence   does not define the extent of modification or dependence on the Original Work   required in order to classify a work as a Derivative Work; this extent is   determined by copyright law applicable in the country mentioned in Article 15.</p> </li> <li> <p>\u2018The Work\u2019: the Original Work or its Derivative Works.</p> </li> <li> <p>\u2018The Source Code\u2019: the human-readable form of the Work which is the most   convenient for people to study and modify.</p> </li> <li> <p>\u2018The Executable Code\u2019: any code which has generally been compiled and which is   meant to be interpreted by a computer as a program.</p> </li> <li> <p>\u2018The Licensor\u2019: the natural or legal person that distributes or communicates   the Work under the Licence.</p> </li> <li> <p>\u2018Contributor(s)\u2019: any natural or legal person who modifies the Work under the   Licence, or otherwise contributes to the creation of a Derivative Work.</p> </li> <li> <p>\u2018The Licensee\u2019 or \u2018You\u2019: any natural or legal person who makes any usage of   the Work under the terms of the Licence.</p> </li> <li> <p>\u2018Distribution\u2019 or \u2018Communication\u2019: any act of selling, giving, lending,   renting, distributing, communicating, transmitting, or otherwise making   available, online or offline, copies of the Work or providing access to its   essential functionalities at the disposal of any other natural or legal   person.</p> </li> <li> <p>Scope of the rights granted by the Licence</p> </li> </ul> <p>The Licensor hereby grants You a worldwide, royalty-free, non-exclusive, sublicensable licence to do the following, for the duration of copyright vested in the Original Work:</p> <ul> <li>use the Work in any circumstance and for all usage,</li> <li>reproduce the Work,</li> <li>modify the Work, and make Derivative Works based upon the Work,</li> <li>communicate to the public, including the right to make available or display   the Work or copies thereof to the public and perform publicly, as the case may   be, the Work,</li> <li>distribute the Work or copies thereof,</li> <li>lend and rent the Work or copies thereof,</li> <li>sublicense rights in the Work or copies thereof.</li> </ul> <p>Those rights can be exercised on any media, supports and formats, whether now known or later invented, as far as the applicable law permits so.</p> <p>In the countries where moral rights apply, the Licensor waives his right to exercise his moral right to the extent allowed by law in order to make effective the licence of the economic rights here above listed.</p> <p>The Licensor grants to the Licensee royalty-free, non-exclusive usage rights to any patents held by the Licensor, to the extent necessary to make use of the rights granted on the Work under this Licence.</p> <ol> <li>Communication of the Source Code</li> </ol> <p>The Licensor may provide the Work either in its Source Code form, or as Executable Code. If the Work is provided as Executable Code, the Licensor provides in addition a machine-readable copy of the Source Code of the Work along with each copy of the Work that the Licensor distributes or indicates, in a notice following the copyright notice attached to the Work, a repository where the Source Code is easily and freely accessible for as long as the Licensor continues to distribute or communicate the Work.</p> <ol> <li>Limitations on copyright</li> </ol> <p>Nothing in this Licence is intended to deprive the Licensee of the benefits from any exception or limitation to the exclusive rights of the rights owners in the Work, of the exhaustion of those rights or of other applicable limitations thereto.</p> <ol> <li>Obligations of the Licensee</li> </ol> <p>The grant of the rights mentioned above is subject to some restrictions and obligations imposed on the Licensee. Those obligations are the following:</p> <p>Attribution right: The Licensee shall keep intact all copyright, patent or trademarks notices and all notices that refer to the Licence and to the disclaimer of warranties. The Licensee must include a copy of such notices and a copy of the Licence with every copy of the Work he/she distributes or communicates. The Licensee must cause any Derivative Work to carry prominent notices stating that the Work has been modified and the date of modification.</p> <p>Copyleft clause: If the Licensee distributes or communicates copies of the Original Works or Derivative Works, this Distribution or Communication will be done under the terms of this Licence or of a later version of this Licence unless the Original Work is expressly distributed only under this version of the Licence \u2014 for example by communicating \u2018EUPL v. 1.2 only\u2019. The Licensee (becoming Licensor) cannot offer or impose any additional terms or conditions on the Work or Derivative Work that alter or restrict the terms of the Licence.</p> <p>Compatibility clause: If the Licensee Distributes or Communicates Derivative Works or copies thereof based upon both the Work and another work licensed under a Compatible Licence, this Distribution or Communication can be done under the terms of this Compatible Licence. For the sake of this clause, \u2018Compatible Licence\u2019 refers to the licences listed in the appendix attached to this Licence. Should the Licensee's obligations under the Compatible Licence conflict with his/her obligations under this Licence, the obligations of the Compatible Licence shall prevail.</p> <p>Provision of Source Code: When distributing or communicating copies of the Work, the Licensee will provide a machine-readable copy of the Source Code or indicate a repository where this Source will be easily and freely available for as long as the Licensee continues to distribute or communicate the Work.</p> <p>Legal Protection: This Licence does not grant permission to use the trade names, trademarks, service marks, or names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the copyright notice.</p> <ol> <li>Chain of Authorship</li> </ol> <p>The original Licensor warrants that the copyright in the Original Work granted hereunder is owned by him/her or licensed to him/her and that he/she has the power and authority to grant the Licence.</p> <p>Each Contributor warrants that the copyright in the modifications he/she brings to the Work are owned by him/her or licensed to him/her and that he/she has the power and authority to grant the Licence.</p> <p>Each time You accept the Licence, the original Licensor and subsequent Contributors grant You a licence to their contributions to the Work, under the terms of this Licence.</p> <ol> <li>Disclaimer of Warranty</li> </ol> <p>The Work is a work in progress, which is continuously improved by numerous Contributors. It is not a finished work and may therefore contain defects or \u2018bugs\u2019 inherent to this type of development.</p> <p>For the above reason, the Work is provided under the Licence on an \u2018as is\u2019 basis and without warranties of any kind concerning the Work, including without limitation merchantability, fitness for a particular purpose, absence of defects or errors, accuracy, non-infringement of intellectual property rights other than copyright as stated in Article 6 of this Licence.</p> <p>This disclaimer of warranty is an essential part of the Licence and a condition for the grant of any rights to the Work.</p> <ol> <li>Disclaimer of Liability</li> </ol> <p>Except in the cases of wilful misconduct or damages directly caused to natural persons, the Licensor will in no event be liable for any direct or indirect, material or moral, damages of any kind, arising out of the Licence or of the use of the Work, including without limitation, damages for loss of goodwill, work stoppage, computer failure or malfunction, loss of data or any commercial damage, even if the Licensor has been advised of the possibility of such damage. However, the Licensor will be liable under statutory product liability laws as far such laws apply to the Work.</p> <ol> <li>Additional agreements</li> </ol> <p>While distributing the Work, You may choose to conclude an additional agreement, defining obligations or services consistent with this Licence. However, if accepting obligations, You may act only on your own behalf and on your sole responsibility, not on behalf of the original Licensor or any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against such Contributor by the fact You have accepted any warranty or additional liability.</p> <ol> <li>Acceptance of the Licence</li> </ol> <p>The provisions of this Licence can be accepted by clicking on an icon \u2018I agree\u2019 placed under the bottom of a window displaying the text of this Licence or by affirming consent in any other similar way, in accordance with the rules of applicable law. Clicking on that icon indicates your clear and irrevocable acceptance of this Licence and all of its terms and conditions.</p> <p>Similarly, you irrevocably accept this Licence and all of its terms and conditions by exercising any rights granted to You by Article 2 of this Licence, such as the use of the Work, the creation by You of a Derivative Work or the Distribution or Communication by You of the Work or copies thereof.</p> <ol> <li>Information to the public</li> </ol> <p>In case of any Distribution or Communication of the Work by means of electronic communication by You (for example, by offering to download the Work from a remote location) the distribution channel or media (for example, a website) must at least provide to the public the information requested by the applicable law regarding the Licensor, the Licence and the way it may be accessible, concluded, stored and reproduced by the Licensee.</p> <ol> <li>Termination of the Licence</li> </ol> <p>The Licence and the rights granted hereunder will terminate automatically upon any breach by the Licensee of the terms of the Licence.</p> <p>Such a termination will not terminate the licences of any person who has received the Work from the Licensee under the Licence, provided such persons remain in full compliance with the Licence.</p> <ol> <li>Miscellaneous</li> </ol> <p>Without prejudice of Article 9 above, the Licence represents the complete agreement between the Parties as to the Work.</p> <p>If any provision of the Licence is invalid or unenforceable under applicable law, this will not affect the validity or enforceability of the Licence as a whole. Such provision will be construed or reformed so as necessary to make it valid and enforceable.</p> <p>The European Commission may publish other linguistic versions or new versions of this Licence or updated versions of the Appendix, so far this is required and reasonable, without reducing the scope of the rights granted by the Licence. New versions of the Licence will be published with a unique version number.</p> <p>All linguistic versions of this Licence, approved by the European Commission, have identical value. Parties can take advantage of the linguistic version of their choice.</p> <ol> <li>Jurisdiction</li> </ol> <p>Without prejudice to specific agreement between parties,</p> <ul> <li> <p>any litigation resulting from the interpretation of this License, arising   between the European Union institutions, bodies, offices or agencies, as a   Licensor, and any Licensee, will be subject to the jurisdiction of the Court   of Justice of the European Union, as laid down in article 272 of the Treaty on   the Functioning of the European Union,</p> </li> <li> <p>any litigation arising between other parties and resulting from the   interpretation of this License, will be subject to the exclusive jurisdiction   of the competent court where the Licensor resides or conducts its primary   business.</p> </li> <li> <p>Applicable Law</p> </li> </ul> <p>Without prejudice to specific agreement between parties,</p> <ul> <li> <p>this Licence shall be governed by the law of the European Union Member State   where the Licensor has his seat, resides or has his registered office,</p> </li> <li> <p>this licence shall be governed by Belgian law if the Licensor has no seat,   residence or registered office inside a European Union Member State.</p> </li> </ul> <p>Appendix</p> <p>\u2018Compatible Licences\u2019 according to Article 5 EUPL are:</p> <ul> <li>GNU General Public License (GPL) v. 2, v. 3</li> <li>GNU Affero General Public License (AGPL) v. 3</li> <li>Open Software License (OSL) v. 2.1, v. 3.0</li> <li>Eclipse Public License (EPL) v. 1.0</li> <li>CeCILL v. 2.0, v. 2.1</li> <li>Mozilla Public Licence (MPL) v. 2</li> <li>GNU Lesser General Public Licence (LGPL) v. 2.1, v. 3</li> <li>Creative Commons Attribution-ShareAlike v. 3.0 Unported (CC BY-SA 3.0) for   works other than software</li> <li>European Union Public Licence (EUPL) v. 1.1, v. 1.2</li> <li>Qu\u00e9bec Free and Open-Source Licence \u2014 Reciprocity (LiLiQ-R) or Strong   Reciprocity (LiLiQ-R+).</li> </ul> <p>The European Commission may update this Appendix to later versions of the above licences without producing a new version of the EUPL, as long as they provide the rights granted in Article 2 of this Licence and protect the covered Source Code from exclusive appropriation.</p> <p>All other changes or additions to this Appendix require the production of a new EUPL version.</p>"},{"location":"logging/","title":"Logging","text":"<p>All DataGEMS services are producing logs in a structured way, usilizing common log formats. The logs are aggregated to the Logging Service where they can be queried and analyzed.</p>"},{"location":"logging/#log-format","title":"Log format","text":"<p>The service utilized serilog for structured logging. The respective Configuration section describes where this is configured. </p> <p>The log format utilized by is compact json providing structured presentation of the information presented. This is easily parsed and made available for further processing.</p>"},{"location":"logging/#correlation-identifier","title":"Correlation Identifier","text":"<p>A key property in enabling troubleshooting in the micro-service DataGEMS architecture is the Correlation Identifier. </p> <p>In order to serve a user request, a number of services invocations may be chained. It will be useful to be able to track the chain of the request across all involved services. To achive this, we utilize a shared Correlation Id that is generated early in the call stack and propagated across all subsequent invocations.</p> <p>At the begining of the request stack, we check if there is a correlation id provided for the request in the request headers typically under a header named x-tracking-correlation. If not, we generate one for the request and any downstream calls. We also add it in the logging configuration so that all subsequent log messages include this correlation id.</p> <p>At the time of invoking another service, we include the correlation id header, along with the correlation id value so that the next service in line will use the same identifier.</p> <p>The respective Configuration section describes where this behavior is configured. </p>"},{"location":"logging/#troubleshooting-logs","title":"Troubleshooting Logs","text":"<p>Troubleshooting logs are produced by the service throughout the execution of caller requests. The messages are separated by the log level:</p> <ul> <li>Trace</li> <li>Debug</li> <li>Information</li> <li>Warning</li> <li>Error</li> <li>Critical</li> </ul> <p>Log entries may contain the following information (where available):</p> <ul> <li>Timestamp in UTC (ISO8601)</li> <li>Correlation Identifier</li> <li>Subject Id</li> <li>Client Id</li> <li>Message text</li> <li>Log Level</li> <li>... additional properties</li> </ul> <p>An prettified example of a log entry is:</p> <pre><code>[\n    {\n        \"@t\": \"2025-08-08T11:13:14.8335054Z\",\n        \"@mt\": \"{\\\"msg\\\":\\\"building\\\",\\\"m\\\":{\\\"type\\\":\\\"Collection\\\",\\\"fields\\\":{\\\"Fields\\\":[\\\"id\\\",\\\"code\\\",\\\"name\\\",\\\"datasetcount\\\"]},\\\"dataCount\\\":5}}\",\n        \"@l\": \"Debug\",\n        \"@tr\": \"c3e3abe1e71da568c1dceb387b19a7ff\",\n        \"@sp\": \"5eee2c1f0d5309b2\",\n        \"SourceContext\": \"DataGEMS.Gateway.App.Model.Builder.CollectionBuilder\",\n        \"ActionId\": \"654d5a3b-9980-4684-a70a-4eedaada7b99\",\n        \"ActionName\": \"DataGEMS.Gateway.Api.Controllers.DatasetController.Query (DataGEMS.Gateway.Api)\",\n        \"RequestId\": \"0HNEMDADKBH0J:00000001\",\n        \"RequestPath\": \"/api/dataset/query\",\n        \"ConnectionId\": \"0HNEMDADKBH0J\",\n        \"ClientId\": null,\n        \"Username\": null,\n        \"UserId\": \"the subject id\",\n        \"DGCorrelationId\": \"the correlation id\",\n        \"MachineName\": \"the machine name\",\n        \"ProcessId\": 1,\n        \"ThreadId\": 19,\n        \"Application\": \"the application id\"\n    },\n    {\n        \"@t\": \"2025-08-08T11:13:14.8357014Z\",\n        \"@mt\": \"HTTP {RequestMethod} {RequestPath} responded {StatusCode} in {Elapsed:0.0000} ms\",\n        \"@r\": [\n            \"38.1723\"\n        ],\n        \"@tr\": \"03cb7b58744f0d0e3ffff2e05ce85ed5\",\n        \"@sp\": \"cfc6357aff7c7c7c\",\n        \"RequestMethod\": \"POST\",\n        \"RequestPath\": \"/api/dataset/query\",\n        \"StatusCode\": 200,\n        \"Elapsed\": 38.172305,\n        \"SourceContext\": \"Serilog.AspNetCore.RequestLoggingMiddleware\",\n        \"DGCorrelationId\": \"the correlation id\",\n        \"RequestId\": \"0HNEMDADKBH0H:00000001\",\n        \"ConnectionId\": \"0HNEMDADKBH0H\",\n        \"MachineName\": \"the machine name\",\n        \"ProcessId\": 1,\n        \"ThreadId\": 19,\n        \"Application\": \"the application id\"\n    }\n]\n</code></pre>"},{"location":"logging/#accounting-logs","title":"Accounting Logs","text":"<p>The service generates accounting entries that utilize the same logging mechanism but are differentiated by troubleshooting logs through the \"SourceContext\" property which is set to \"accounting\".</p> <p>These accounting log entries are harvested and processed by the Accounting Service</p> <p>A prettified example of an accounting log entry is: <pre><code>{\n    \"@t\": \"2025-08-08T11:13:14.8354027Z\",\n    \"@mt\": \"{\\\"m\\\":{\\\"timestamp\\\":\\\"2025-08-08T11:13:14.8353562Z\\\",\\\"serviceId\\\":\\\"the service id\\\",\\\"action\\\":\\\"Query\\\",\\\"resource\\\":\\\"Dataset\\\",\\\"userId\\\":\\\"the subject id\\\",\\\"value\\\":\\\"1\\\",\\\"measure\\\":\\\"Unit\\\",\\\"type\\\":\\\"+\\\"}}\",\n    \"@tr\": \"03cb7b58744f0d0e3ffff2e05ce85ed5\",\n    \"@sp\": \"cfc6357aff7c7c7c\",\n    \"SourceContext\": \"accounting\",\n    \"ActionId\": \"654d5a3b-9980-4684-a70a-4eedaada7b99\",\n    \"ActionName\": \"DataGEMS.Gateway.Api.Controllers.DatasetController.Query (DataGEMS.Gateway.Api)\",\n    \"RequestId\": \"0HNEMDADKBH0H:00000001\",\n    \"RequestPath\": \"/api/dataset/query\",\n    \"ConnectionId\": \"0HNEMDADKBH0H\",\n    \"ClientId\": null,\n    \"Username\": null,\n    \"UserId\": \"the subject id\",\n    \"DGCorrelationId\": \"the correlation id\",\n    \"MachineName\": \"the machine name\",\n    \"ProcessId\": 1,\n    \"ThreadId\": 19,\n    \"Application\": \"the application id\"\n}\n</code></pre></p> <p>The @mt property contains the information that is intended to be utilized by the accounting service to track this action: <pre><code>{\n    \"m\": {\n        \"timestamp\": \"2025-08-08T11:13:14.8353562Z\",\n        \"serviceId\": \"the service id\",\n        \"action\": \"Query\",\n        \"resource\": \"Dataset\",\n        \"userId\": \"the subject id\",\n        \"value\": \"1\",\n        \"measure\": \"Unit\",\n        \"type\": \"+\"\n    }\n}\n</code></pre></p>"},{"location":"onboarding/","title":"Onboarding Material","text":"<p>This section contains some references and material that will assist users and integrators onboarding process.</p>"},{"location":"onboarding/#references","title":"References","text":""},{"location":"onboarding/#tutorials","title":"Tutorials","text":"<p>You can find useful material and onboarding guidelines in our social channels bellow, as well as our platform documentation.</p>"},{"location":"onboarding/#keep-in-touch","title":"Keep in touch","text":"<p>Make sure to follow the DataGEMS channels to get the latest news and references:</p> <ul> <li>GitHub</li> <li>Instagram</li> <li>X</li> <li>YoutTube</li> <li>LinkedIn</li> <li>Facebook</li> </ul>"},{"location":"qa/","title":"Quality Assurance","text":"<p>Key aspects of the Quality Assurance checklist that DataGEMS services must pass have been defined in the processes and documents governing the platform development and quality assurance. In this section we present a selected subset of these that are directly, publicly available.</p>"},{"location":"qa/#code-analysis","title":"Code Analysis","text":"<p>Static code analysis is the process of examining source code without executing it, to identify potential errors, vulnerabilities, or deviations from coding standards. It is typically performed using tools that analyze the code's structure, syntax, and logic to detect issues such as bugs, security flaws, or maintainability problems early in the development cycle. This helps improve code quality, reduce technical debt, and ensure compliance with best practices before the software is run or deployed.</p> <p>Static code analysis is a process that has been tied with the development and release lifecycle through the configured GitHub Actions workflow that performs security, quality and maintenability of the code base. The workflow is described in the relevant Automations section.</p>"},{"location":"qa/#code-metrics","title":"Code Metrics","text":"<p>Code metrics are quantitative measurements used to assess various aspects of source code quality and complexity. They help developers understand how maintainable, efficient, and error-prone a codebase might be. Common code metrics include lines of code (LOC), cyclomatic complexity, maintenability index, and coupling levels. By analyzing these metrics, teams can identify potential issues, enforce coding standards, and improve overall software quality throughout the development lifecycle.</p> <p>The service has configured an automated GitHub Actions workflow, as described in the relevant Automations section to calculate such metrics.</p>"},{"location":"qa/#vulnerability-checks","title":"Vulnerability checks","text":"<p>Vulnerability checks are processes used to identify known security weaknesses in software, libraries, or dependencies. These checks typically scan the codebase, configuration files, or external packages against databases of publicly disclosed vulnerabilities. By detecting issues such as outdated libraries, insecure functions, or misconfigurations, vulnerability checks help developers address security risks early and maintain a secure software environment.</p> <p>The service has configured an automated GitHub Actions workflow, as described in the relevant Automations section to perform such checks on the versioned artefacts.</p>"},{"location":"qa/#testing","title":"Testing","text":"<p>TODO: Describe the process</p>"},{"location":"security/","title":"Security","text":"<p>Key aspects of the Security checklist and practices that DataGEMS services must pass have been defined in the processes and documents governing the platform development and quality assurance. In this section we present a selected subset of these that are directly, publicly available and affect the usage and configuration of the service.</p>"},{"location":"security/#authentication","title":"Authentication","text":"<p>All endpoints exposed by this service require authentication using Bearer tokens in the form of JWTs (JSON Web Tokens). Clients must include a valid token in the Authorization header of each HTTP request, using the following format:</p> <pre><code>Authorization: Bearer &lt;token&gt;\n</code></pre> <p>The service only accepts JWTs that are issued by a trusted identity provider, the DataGEMS AAI service. This issuer is responsible for authenticating users and issuing tokens with claims that the service can validate. One of the critical claims in the token is the aud (audience) claim. The value of this claim must include the identifier of this service, ensuring that the token was intended to be used with it.</p> <p>When a token is received, the service performs a series of validation steps before granting access to any endpoint. These steps typically include verifying the token\u2019s signature using the public keys published by the trusted issuer, checking the issuer iss claim to confirm it matches the expected DataGEMS AAI issuer, validating the audience aud claim to ensure the token was meant for this service, and checking the token expiration exp to confirm the token is still valid. Only if all these checks pass will the request be authenticated and passed for further processing.</p> <p>The location of the configuration governing the specific behavior is described in teh relevant Configuration section.</p>"},{"location":"security/#authorization","title":"Authorization","text":"<p>When an authenticated call reaches the service, the caller may be authorized to perform an action or not. This will have to be authorized based on the grants that are present as roles in the access token presented as well as the context in which they want to perform the operation.</p> <p>Within the service, all data access operations as well as individual actions pass authorization checks. The permissions that are checked along with the policies attached to each one is managed in a configuration file that the respective Configuration section describes.</p> <p>Possible authorization policies include: * Context-less assignment: such as an administrator that can perform action X on entity Y, regardless of the kind of affiliation they have with the entity * Context: An affiliation of the calling user with the entity over which the action is to be performed. The context policy it tied to an anchor entity that is treated as the affiliation bearer. In the context of DataGEMS, this entity is the Dataset * Owner: Specific kind of affiliation between the calling user and the entity over which the action is to be performed, indicating ownership of the entity. An example is a User Collection that is owned by a specific user * Claim: a policy similar to the Context-less permission assignment. Instead of checking specificaly the \"role\" claim type, this policy will check ad-hoc claims that have specific values to match the policy * Client: a policy similar to the Context-less permission assignment. Instead of checking specificaly the \"role\" claim type, this policy will check the caller client id to have a specific value to match the policy * Authenticated: Authenticated user, regardless of any other characteristic vcan be granted or not granted the specific permission * Anonymous: Anonymous users be be granted or not granted the specific permission</p> <p>For context based authorization policies with a Dataset affiliation bearer, the evaluation of the kind of operations that the user can perfomr is done by interpreting the respective JWT \"datasets\" claim. The context is provided through the interpretation of the context grant model detailed in the DataGEMS AAI.</p> <p>For each of affiliation bearing datasets, the following actions (verbs) are interpreted to grant needed access: * browse - Grants permission to browse the dataset in a listing view and see dataset metadata * delete - Grants permission to delete the dataset * download - Grants permission to download the dataset * edit - Grants permission to edit dataset data and metadata * search - Grants permission to perform a search using the data and metadata of the dataset. This does not refer to listing / browsing operations but advanced search capabilities offered by DataGEMS</p>"},{"location":"security/#token-exchange","title":"Token exchange","text":"<p>In the microservice architecture of DataGEMS and given the role of the Gateway Api in the DataGEMS archtiecture, it is expected that the service will need to invoke other services, either outside or within the request flow of an external invocation. The service  may need to perform some out of band operation or a scheduled maintenance / system task. Or, within the context of an incoming communication, invoke a third service as part of fulfilling its operation. We separate these two cases to distinguish the authentication mechanisms that are used:</p> <ul> <li> <p>Service to Service with Client Credentials: The service needs to acquire an access token that it can present to the service it is invoking. It will initiate a client credential flow, presenting it's client id and secret, along with the scope of the access token which will indicate the audience / reciever of the generated credential. The genereted access token can then be used in the HTTP request as a Bearer token in the Authorization header.</p> </li> <li> <p>Service to Service with Exchanged Credentials: The service, in the context of serving a user request needs to invoke another service. It must forward the credentials it was invoked with to continue the process flow under the scope of the original caller. It will initiate a token exchange flow, presenting it's client id and secret so that the AAI service authorizes the client to exhcnage the requested token, along with the initial access token that needs to be exchanged and the desired scope of the new access token which will indicate the audience / reciever of the generated, exchanged credential. The genereted access token can then be used in the HTTP request as a Bearer token in the Authorization header.</p> </li> </ul> <p>These two flows are supported by the DataGEMS AAI service and the needed configuration is located as the respective Configuration section describes.</p>"},{"location":"security/#secrets","title":"Secrets","text":"<p>Secrets are a special kind of configuration that requires special handling. This is described in the respective Configuration section.</p>"}]}